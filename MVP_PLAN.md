# MVP 版本規劃

## 核心目標
建立一個最小可行的語音對話測試平台，驗證 Google Live API 的基本功能。

## MVP 功能範圍

### 必要功能
1. **雙重語音輸入方式**：
   - Push-to-Talk（按住說話）
   - 連續對話模式（持續監聽與自動回應）
2. **文字輸入**：支援文字訊息發送
3. **Thread 管理**：
   - 建立新對話
   - 切換不同對話
   - 查看歷史對話
4. **即時轉錄**：顯示語音識別結果
5. **語音設定調整**：
   - 語速控制
   - 音量調節
   - 語音選擇（如果 API 支援）

### 技術選擇（更新版）
- **前端**：React + TypeScript（需要狀態管理）
- **後端**：Node.js + Express + WebSocket
- **資料儲存**：SQLite（輕量級，適合 MVP）
- **部署**：本地開發環境

### 簡化但保留的功能
- ✅ 基本用戶區分（用 localStorage 或 session）
- ✅ 對話持久化（存在 SQLite）
- ✅ 基礎 UI/UX（使用現成元件庫）

### 暫不包含的功能
- ❌ 完整用戶認證系統
- ❌ 多語言自動切換
- ❌ 進階分析功能
- ❌ 雲端部署

## 實作步驟

### Phase 1: 環境設置
1. 取得 Google Live API 存取權限
2. 建立基本專案結構
3. 設定開發環境

### Phase 2: 後端實作
1. WebSocket 服務器設置
2. Google Live API 連接
3. 音頻流處理

### Phase 3: 前端實作
1. 基本 UI 介面
2. 麥克風存取
3. 音頻錄製和發送
4. 顯示轉錄結果

### Phase 4: 整合測試
1. 端到端測試
2. 錯誤處理
3. 基本優化

## 成功標準
- ✅ 三種輸入方式都能正常運作（文字、按鈕語音、連續對話）
- ✅ 系統能即時顯示語音轉文字
- ✅ AI 能用語音回應，且可調整語音設定
- ✅ Thread 管理功能完整（新增、切換、歷史查看）
- ✅ 對話能持久保存並恢復

## 時程估計
- 環境設置：3-4 小時
- 後端開發：8-10 小時
  - WebSocket 連接：2 小時
  - Google Live API 整合：3 小時
  - Thread 管理 API：3 小時
- 前端開發：10-12 小時
  - 基礎 UI 架構：2 小時
  - 三種輸入模式：4 小時
  - Thread 管理介面：3 小時
  - 語音設定介面：2 小時
- 整合測試：4-5 小時
- **總計：25-31 小時**